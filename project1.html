<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Naive Bayes And Sailor Search</title>
        <link rel="stylesheet" href="style.css">
        <script src="https://kit.fontawesome.com/83c6b17d5b.js" crossorigin="anonymous"></script>
    </head>
    <body>
        <div id="header">
            <div class="container">
                <nav>
                    <img src="images/logo.png" class="logo">
                    <ul id="sidemenu">
                        <li><a href="index.html">Home</a></li>
                        <i class="fa-solid fa-xmark" onclick="closemenu()"></i>
                    </ul>
                    <i class="fa-solid fa-bars" onclick="openmenu()"></i>
                </nav>
                
<!-- Project -->
<div id="Project">
    <div class="container1">
        <article>
            <header>
                <h2>Finding Lost Sailors Using Naïve Bayes</h2>
            </header>
            <section>
                <p>In 1763, Richard Price, a moral philosopher, introduced the essay, “An Essay Towards Solving a Problem in the Indoctrine of Chances,” by Thomas Bayes. Naïve Bayes theorem is now a fundamental tool in statistical and Machine Learning. However, the origins of this tool are very unexpected. This theorem was invented by an English Presbyterian minister in an attempt to prove God’s existence. Thomas Bayes passed away in the year 1763, however, his essay was posthumously published in 1766 by Price. However, during the time of its publication, the essay was not given it’s right recognition, as the mathematics was too extensive to prove. It wasn’t until the invention of the modern computer, with fast processors, that we found the full potential of this mathematical tool. </p>
            </section>
            <section>
                <h3>So what Is Naïve Bayes Theorem?</h3>
                <p>This theorem allows us to mathematically incorporate data correctly, and calculate the probabilities of an event. It’s a tool that is versatile because it penetrates almost all questions that come to mind, from healthcare-related probabilities to coding to presidential elections. The Bayes’ rule helps us determine the probability that something is true with a given set of events.</p>
                <div class="formula">
                    <strong>Bayes' Rule:</strong><br>
                    \( P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)} \)
                </div>
                <p>Here, A is the hypothesis and B is data. \( P(A|B) \) means the probability of A given B. \( P(B|A) \) means the probability of B given A.</p>
                <p>Example:</p>
                <div class="formula">
                    <strong>Bayes' Rule Example:</strong><br>
                    \( P(\text{Cancer}|\text{Positive Test}) = \frac{P(\text{Positive Test}|\text{Cancer}) \cdot P(\text{Cancer})}{P(\text{Positive Test})} \)
                </div>
                <p>So here the initial probabilities would be based on clinical outcomes.</p>
            </section>
            <!-- Add more sections for additional content -->
        </article>
    </div>
    <footer class="copyright">
        <p> Copyright © Kashish. Designed for excellence <i class="fa-solid fa-trophy"></i></p>
    </footer>
</div>
</body>
</html>




